{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "258991d2",
   "metadata": {},
   "source": [
    "### Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "056618cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f68fea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d07fd380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AgenticAI'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53573fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"]=os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "## Langsmith Tracking And Tracing\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3391038f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x0000022C168D71A0> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000022C168D7EF0> root_client=<openai.OpenAI object at 0x0000022C1662CAA0> root_async_client=<openai.AsyncOpenAI object at 0x0000022C1662CC50> model_name='o1-mini' temperature=1.0 model_kwargs={} openai_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import  ChatOpenAI\n",
    "openai_llm =  ChatOpenAI(model=\"o1-mini\")\n",
    "print(openai_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6e85fead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='**Agentic AI** refers to artificial intelligence systems designed to act as autonomous agents, capable of making decisions and taking actions toward achieving specific goals without continuous human supervision. The term \"agentic\" emphasizes the AI\\'s ability to exhibit agencyâ€”the capacity to act independently and make choices based on its programming, learned experiences, and interactions with its environment.\\n\\n### Key Characteristics of Agentic AI\\n\\n1. **Autonomy**: Agentic AI systems operate independently, making decisions without needing real-time human intervention. They can initiate actions based on their assessments and objectives.\\n\\n2. **Reactivity**: These AI agents can perceive their environment through sensors or data inputs and respond to changes or stimuli in a timely manner.\\n\\n3. **Proactiveness**: Beyond just reacting, agentic AI can anticipate future states or needs, allowing it to take initiative to achieve long-term goals.\\n\\n4. **Goal-Oriented Behavior**: They are programmed with specific objectives. Their actions are directed toward fulfilling these goals efficiently and effectively.\\n\\n5. **Learning and Adaptation**: Agentic AI systems often incorporate machine learning algorithms that enable them to learn from experiences, adapt to new situations, and improve their performance over time.\\n\\n6. **Decision-Making Capability**: They can evaluate multiple options, weigh potential outcomes, and choose the best course of action based on predefined criteria or learned preferences.\\n\\n### Applications of Agentic AI\\n\\n- **Autonomous Vehicles**: Self-driving cars navigate roads, make real-time decisions, and respond to dynamic traffic conditions without human input.\\n  \\n- **Robotic Assistants**: In industries like manufacturing or healthcare, robots perform tasks such as assembling products or assisting in surgeries autonomously.\\n  \\n- **Personal Virtual Assistants**: AI like Siri or Alexa can manage schedules, control smart home devices, and perform tasks based on user preferences and behaviors.\\n  \\n- **Financial Trading Systems**: AI agents execute trades, manage portfolios, and respond to market changes in real-time to optimize financial returns.\\n  \\n- **Customer Service Bots**: Advanced chatbots handle inquiries, resolve issues, and provide personalized support without human operators.\\n\\n### Benefits of Agentic AI\\n\\n- **Efficiency and Speed**: Autonomous agents can process information and execute tasks faster than humans, leading to increased productivity.\\n  \\n- **24/7 Operation**: Unlike humans, agentic AI can work continuously without fatigue, ensuring constant availability and service.\\n  \\n- **Handling Complex Tasks**: They can manage and analyze vast amounts of data, identifying patterns and insights that may be challenging for humans to discern.\\n\\n- **Consistency**: Agentic AI can perform tasks uniformly without the variability associated with human performance.\\n\\n### Challenges and Considerations\\n\\n- **Ethical Concerns**: Decisions made by autonomous agents can raise questions about accountability, especially if they lead to unintended or harmful outcomes.\\n  \\n- **Bias and Fairness**: If the data or algorithms underpinning agentic AI are biased, the actions and decisions of these agents can perpetuate or amplify existing biases.\\n  \\n- **Security Risks**: Autonomous agents could be vulnerable to hacking or malicious manipulation, leading to potential misuse.\\n  \\n- **Job Displacement**: The rise of agentic AI in various industries may lead to displacement of certain job roles, necessitating workforce reskilling and adaptation.\\n  \\n- **Transparency and Explainability**: Understanding how agentic AI makes decisions is crucial, especially in sectors like healthcare or law, where explanations for actions are necessary.\\n\\n### Future Outlook\\n\\nAgentic AI continues to evolve, driven by advancements in machine learning, natural language processing, and robotics. Researchers are focused on enhancing the autonomy, adaptability, and ethical frameworks governing these systems to ensure they act in alignment with human values and societal norms. As agentic AI becomes more integrated into daily life and various industries, ongoing dialogue between technologists, policymakers, and the public will be essential to navigate its complexities and maximize its benefits while mitigating potential risks.\\n\\nIn summary, **Agentic AI** represents a significant stride in artificial intelligence, embodying systems that can autonomously act and make decisions. While offering numerous advantages in efficiency and capability, it also necessitates careful consideration of ethical, societal, and technical challenges to ensure its responsible and beneficial deployment.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 1376, 'prompt_tokens': 13, 'total_tokens': 1389, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 512, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'o1-mini-2024-09-12', 'system_fingerprint': 'fp_3da8b0b088', 'id': 'chatcmpl-BgxusbWASjytGYhDxf4WkbMe8K2vO', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--b342d4f5-e2e5-4623-bd3b-aada1645e93b-0' usage_metadata={'input_tokens': 13, 'output_tokens': 1376, 'total_tokens': 1389, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 512}}\n",
      "------------------------------------------------------------\n",
      "**Agentic AI** refers to artificial intelligence systems designed to act as autonomous agents, capable of making decisions and taking actions toward achieving specific goals without continuous human supervision. The term \"agentic\" emphasizes the AI's ability to exhibit agencyâ€”the capacity to act independently and make choices based on its programming, learned experiences, and interactions with its environment.\n",
      "\n",
      "### Key Characteristics of Agentic AI\n",
      "\n",
      "1. **Autonomy**: Agentic AI systems operate independently, making decisions without needing real-time human intervention. They can initiate actions based on their assessments and objectives.\n",
      "\n",
      "2. **Reactivity**: These AI agents can perceive their environment through sensors or data inputs and respond to changes or stimuli in a timely manner.\n",
      "\n",
      "3. **Proactiveness**: Beyond just reacting, agentic AI can anticipate future states or needs, allowing it to take initiative to achieve long-term goals.\n",
      "\n",
      "4. **Goal-Oriented Behavior**: They are programmed with specific objectives. Their actions are directed toward fulfilling these goals efficiently and effectively.\n",
      "\n",
      "5. **Learning and Adaptation**: Agentic AI systems often incorporate machine learning algorithms that enable them to learn from experiences, adapt to new situations, and improve their performance over time.\n",
      "\n",
      "6. **Decision-Making Capability**: They can evaluate multiple options, weigh potential outcomes, and choose the best course of action based on predefined criteria or learned preferences.\n",
      "\n",
      "### Applications of Agentic AI\n",
      "\n",
      "- **Autonomous Vehicles**: Self-driving cars navigate roads, make real-time decisions, and respond to dynamic traffic conditions without human input.\n",
      "  \n",
      "- **Robotic Assistants**: In industries like manufacturing or healthcare, robots perform tasks such as assembling products or assisting in surgeries autonomously.\n",
      "  \n",
      "- **Personal Virtual Assistants**: AI like Siri or Alexa can manage schedules, control smart home devices, and perform tasks based on user preferences and behaviors.\n",
      "  \n",
      "- **Financial Trading Systems**: AI agents execute trades, manage portfolios, and respond to market changes in real-time to optimize financial returns.\n",
      "  \n",
      "- **Customer Service Bots**: Advanced chatbots handle inquiries, resolve issues, and provide personalized support without human operators.\n",
      "\n",
      "### Benefits of Agentic AI\n",
      "\n",
      "- **Efficiency and Speed**: Autonomous agents can process information and execute tasks faster than humans, leading to increased productivity.\n",
      "  \n",
      "- **24/7 Operation**: Unlike humans, agentic AI can work continuously without fatigue, ensuring constant availability and service.\n",
      "  \n",
      "- **Handling Complex Tasks**: They can manage and analyze vast amounts of data, identifying patterns and insights that may be challenging for humans to discern.\n",
      "\n",
      "- **Consistency**: Agentic AI can perform tasks uniformly without the variability associated with human performance.\n",
      "\n",
      "### Challenges and Considerations\n",
      "\n",
      "- **Ethical Concerns**: Decisions made by autonomous agents can raise questions about accountability, especially if they lead to unintended or harmful outcomes.\n",
      "  \n",
      "- **Bias and Fairness**: If the data or algorithms underpinning agentic AI are biased, the actions and decisions of these agents can perpetuate or amplify existing biases.\n",
      "  \n",
      "- **Security Risks**: Autonomous agents could be vulnerable to hacking or malicious manipulation, leading to potential misuse.\n",
      "  \n",
      "- **Job Displacement**: The rise of agentic AI in various industries may lead to displacement of certain job roles, necessitating workforce reskilling and adaptation.\n",
      "  \n",
      "- **Transparency and Explainability**: Understanding how agentic AI makes decisions is crucial, especially in sectors like healthcare or law, where explanations for actions are necessary.\n",
      "\n",
      "### Future Outlook\n",
      "\n",
      "Agentic AI continues to evolve, driven by advancements in machine learning, natural language processing, and robotics. Researchers are focused on enhancing the autonomy, adaptability, and ethical frameworks governing these systems to ensure they act in alignment with human values and societal norms. As agentic AI becomes more integrated into daily life and various industries, ongoing dialogue between technologists, policymakers, and the public will be essential to navigate its complexities and maximize its benefits while mitigating potential risks.\n",
      "\n",
      "In summary, **Agentic AI** represents a significant stride in artificial intelligence, embodying systems that can autonomously act and make decisions. While offering numerous advantages in efficiency and capability, it also necessitates careful consideration of ethical, societal, and technical challenges to ensure its responsible and beneficial deployment.\n"
     ]
    }
   ],
   "source": [
    "result = openai_llm.invoke(\"What is Agentic AI\")\n",
    "print(result)\n",
    "print('----'*15)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "79c81a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='\\n<think>\\nOkay, the user said \"Hi My name is Ram\". I need to respond appropriately. Let me start by greeting them back. Maybe say hello and mention their name so it feels personal. I should ask how I can assist them today. Keep it friendly and open-ended to encourage them to ask for help. Let me check for any typos or errors. Alright, that should work.\\n\\nWait, should I use an emoji? Maybe a smiley to keep it friendly. But not overdo it. Hmm, maybe just a simple one. Okay, \"Hi Ram! ðŸ‘‹ How can I assist you today?\" That sounds good. Yeah, that\\'s a proper response. No need to complicate it further. Let me make sure the tone is rightâ€”polite and helpful. Yep, that should do it.\\n</think>\\n\\nHi Ram! ðŸ‘‹ How can I assist you today?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 180, 'prompt_tokens': 15, 'total_tokens': 195, 'completion_time': 0.415119085, 'prompt_time': 0.003620366, 'queue_time': 0.314097214, 'total_time': 0.418739451}, 'model_name': 'qwen-qwq-32b', 'system_fingerprint': 'fp_9faf42d81f', 'finish_reason': 'stop', 'logprobs': None}, id='run--22352932-7632-4196-9be0-89fe21ef42f3-0', usage_metadata={'input_tokens': 15, 'output_tokens': 180, 'total_tokens': 195})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model = ChatGroq(model=\"qwen-qwq-32b\")\n",
    "model.invoke(\"Hi My name is Ram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c3579ab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are Expert in AI Enineer.Provide me answer based on the question'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Prompt Engineering\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are Expert in AI Enineer.Provide me answer based on the question\"),\n",
    "        ('user',\"{input}\")\n",
    "    ]  \n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8aab59b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000022C1E3E8E60>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000022C1E40A960>, model_name='gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model = ChatGroq(model=\"gemma2-9b-it\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d6cda409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are Expert in AI Enineer.Provide me answer based on the question'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000022C1E3E8E60>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000022C1E40A960>, model_name='gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### chaining\n",
    "chain = prompt|model\n",
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d123ae16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As an AI engineer, I can definitely tell you about Langsmith! \n",
      "\n",
      "Langsmith is **an open-source platform designed to simplify the development and deployment of large language models (LLMs).** Think of it as a toolkit specifically built for working with powerful AI models like those found in OpenAI's API. \n",
      "\n",
      "Here's a breakdown of what makes Langsmith special:\n",
      "\n",
      "**Key Features:**\n",
      "\n",
      "* **User-Friendly Interface:** Langsmith provides a web-based interface that makes it easier for developers (and even non-developers) to interact with LLMs. \n",
      "* **Streamlined Development:** It offers tools for fine-tuning existing LLMs, creating custom model pipelines, and experimenting with different prompt engineering techniques.\n",
      "* **Modular Design:** Langsmith is built on a modular architecture, allowing developers to easily integrate their own code and tools into the platform.\n",
      "* **Open-Source and Collaborative:** Being open-source means the community can contribute to its development, share resources, and build upon existing work.\n",
      "\n",
      "**Benefits:**\n",
      "\n",
      "* **Reduced Development Time:** Streamlined tools and a user-friendly interface accelerate the LLM development process.\n",
      "* **Enhanced Experimentation:** Langsmith encourages experimentation with different models, prompts, and techniques.\n",
      "* **Increased Accessibility:** By lowering the barrier to entry, Langsmith makes LLMs more accessible to a wider range of users.\n",
      "\n",
      "**How it Works:**\n",
      "\n",
      "Langsmith connects to various LLM APIs (like OpenAI's) and provides a structured way to:\n",
      "\n",
      "* **Send prompts to the LLM:** You can interact with the model through a chat-like interface or by writing code.\n",
      "* **Receive and process the LLM's output:** Langsmith helps you understand and utilize the model's responses.\n",
      "* **Fine-tune the LLM:** You can adjust the model's parameters to improve its performance on specific tasks.\n",
      "\n",
      "**Overall, Langsmith is a powerful platform that empowers developers to leverage the capabilities of LLMs in innovative and efficient ways.**\n",
      "\n",
      "\n",
      "Let me know if you have any other questions about Langsmith or LLMs in general!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke({\"input\":\"Can you tell me something about Langsmith\"})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c149f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're likely thinking of **LangChain**. ðŸ˜Š\n",
      "\n",
      "LangChain is an open-source framework designed to help developers build applications powered by large language models (LLMs). \n",
      "\n",
      "Here's a breakdown of what makes LangChain special:\n",
      "\n",
      "* **Modular Design:** LangChain breaks down the process of building LLM applications into smaller, reusable components called \"chains.\" This allows developers to easily combine different LLMs, tools, and data sources to create complex applications.\n",
      "* **Chain Composability:** Chains can be nested within each other, allowing for the creation of sophisticated workflows and applications.\n",
      "* **Tool Integration:** LangChain supports integration with a wide range of external tools, such as search engines, APIs, and databases, enabling LLMs to perform more than just text generation.\n",
      "* **Memory Management:** LangChain provides mechanisms for managing the memory of LLMs, allowing them to remember past interactions and maintain context within conversations.\n",
      "* **Agents:** LangChain allows developers to build autonomous agents that can interact with the world by executing actions based on LLM-generated instructions.\n",
      "\n",
      "**In essence, LangChain acts as a bridge between LLMs and the real world, empowering developers to build powerful and innovative applications.**\n",
      "\n",
      "Let me know if you have any more questions about LangChain or anything else!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##Without using the PromptChatTemplate\n",
    "response = model.invoke(\"Can you tell me something about Langsmith\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a89d140d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Let's Talk Langsmith!\n",
      "\n",
      "As an AI engineer, I'm familiar with Langsmith. It's a powerful open-source tool designed to simplify the process of building and deploying large language models (LLMs). \n",
      "\n",
      "**Here's a breakdown of what Langsmith offers:**\n",
      "\n",
      "**1. Streamlined Development:**\n",
      "\n",
      "* **Model Training:** Langsmith provides a user-friendly interface and pre-built components to streamline the LLM training process. You can leverage existing models or fine-tune them for specific tasks.\n",
      "* **Experiment Tracking:** It allows you to track your experiments efficiently, comparing different model architectures, hyperparameters, and datasets.\n",
      "* **Data Management:**  Langsmith helps manage your training data, making it easier to preprocess, clean, and integrate with your models.\n",
      "\n",
      "**2. Deployment & Collaboration:**\n",
      "\n",
      "* **API Integration:**  Easily deploy your trained models as APIs, making them accessible for integration into applications and workflows.\n",
      "* **Collaborative Development:** Langsmith fosters collaboration by allowing multiple developers to work on the same project simultaneously.\n",
      "\n",
      "**3. Key Features:**\n",
      "\n",
      "* **Python-based:**  Built on Python, making it accessible to a wide range of developers.\n",
      "* **Modular Design:**  Langsmith's modular architecture allows for customization and extensibility, enabling you to tailor it to your specific needs.\n",
      "* **Open Source:** Being open source, Langsmith benefits from a vibrant community that contributes to its development and provides support.\n",
      "\n",
      "**4. Advantages:**\n",
      "\n",
      "* **Reduced Development Time:**  Langsmith accelerates the development cycle by providing pre-built components and streamlining workflows.\n",
      "* **Improved Efficiency:**  Its features like experiment tracking and data management enhance productivity and efficiency.\n",
      "* **Cost-Effectiveness:** As an open-source tool, Langsmith eliminates licensing costs associated with proprietary solutions.\n",
      "\n",
      "**5. Use Cases:**\n",
      "\n",
      "* **Chatbots & Conversational AI:**  Build intelligent chatbots for customer service, education, or entertainment.\n",
      "* **Text Generation:**  Generate creative content, summarize text, translate languages, or write code.\n",
      "* **Data Analysis & Insights:**  Extract valuable insights from unstructured text data.\n",
      "\n",
      "**Overall, Langsmith is a powerful and versatile tool for anyone looking to leverage the capabilities of LLMs. Its user-friendly interface, open-source nature, and comprehensive features make it an excellent choice for both beginners and experienced AI developers.**\n",
      "\n",
      "\n",
      "Let me know if you have any more questions about Langsmith or any other AI-related topics!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Output Paerser\n",
    "from langchain_core.output_parsers import StrOutputParser \n",
    "output_parser = StrOutputParser() \n",
    "##Chain with parser\n",
    "chain = prompt | model | output_parser \n",
    "##Invoke\n",
    "response = chain.invoke({\"input\":\"Can you tell me about Langsmith\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7375f522",
   "metadata": {},
   "source": [
    "### JSON Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9bcf2d12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Return a JSON object.'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "output_parser=JsonOutputParser()\n",
    "output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7298b494",
   "metadata": {},
   "outputs": [],
   "source": [
    "### OutputParser\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "output_parser = JsonOutputParser()\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query \\n {format_instruction}\\n {query}\\n \",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instruction\":output_parser.get_format_instructions()},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e1a653b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['query'], input_types={}, partial_variables={'format_instruction': 'Return a JSON object.'}, template='Answer the user query \\n {format_instruction}\\n {query}\\n ')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "53476586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Langsmith', 'description': 'Langsmith is an open-source platform for developing and deploying AI applications.', 'features': ['A unified platform for building, training, and deploying AI models.', 'Modular design allows for customization and extensibility.', 'Supports various AI frameworks and libraries.', 'Provides tools for data management, model monitoring, and debugging.', 'Community-driven and actively developed.'], 'use_cases': ['Chatbots and conversational AI', 'Text generation and summarization', 'Code generation and completion', 'Sentiment analysis and classification', 'Machine translation'], 'website': 'https://github.com/langsmithai/langsmith'}\n"
     ]
    }
   ],
   "source": [
    "chain = prompt|model|output_parser\n",
    "response = chain.invoke({\"query\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c389de11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer.Provide the response in json.Provide me answer based on the question'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Assisgnment ---Chatprompttemplate\n",
    "\n",
    "### Prompt Engineering\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are an expert AI Engineer.Provide the response in json.Provide me answer based on the question\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addd7a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'Langsmith is an open-source tool developed by the AI21 Labs research team. It simplifies the process of fine-tuning large language models (LLMs) for specific tasks. \\n\\nHere are some key features and aspects of Langsmith:\\n\\n* **User-Friendly Interface:** Langsmith provides a web-based interface that makes fine-tuning accessible to a wider audience, even those without extensive technical expertise in machine learning.\\n\\n* **Streamlined Workflow:** It offers a simplified workflow for fine-tuning, guiding users through the process of preparing data, selecting a pre-trained LLM, and configuring fine-tuning parameters.\\n\\n* **Fine-Tuning Techniques:** Langsmith supports various fine-tuning techniques, including prompt tuning, parameter-efficient fine-tuning, and adapter modules, allowing users to choose the best method for their specific task.\\n\\n* **Performance Monitoring:** It includes tools for monitoring the performance of the fine-tuning process, enabling users to track progress and make adjustments as needed.\\n\\n* **Community-Driven:** As an open-source project, Langsmith benefits from the contributions and feedback of a growing community of developers and researchers.\\n\\n**Use Cases:**\\n\\nLangsmith can be used to fine-tune LLMs for a wide range of applications, such as:\\n\\n* **Text Generation:** Improving the quality and coherence of text generated by LLMs.\\n* **Question Answering:** Enhancing the accuracy and relevance of answers provided by LLMs.\\n* **Summarization:** Creating concise and informative summaries of text.\\n* **Dialogue Systems:** Training LLMs to engage in more natural and engaging conversations.\\n\\n**Benefits:**\\n\\n* **Accessibility:** Makes fine-tuning LLMs more accessible to a broader user base.\\n* **Efficiency:** Streamlines the fine-tuning process, saving time and resources.\\n* **Customization:** Allows users to tailor LLMs to their specific needs and domains.\\n* **Innovation:** Fosters innovation by enabling experimentation with different fine-tuning techniques.'}\n"
     ]
    }
   ],
   "source": [
    "chain = prompt|model|output_parser\n",
    "response = chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "be28387c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer.<response><answer>Your answer here</answer></response>.Provide me answer based on the question'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### OutputParser\n",
    "from langchain_core.output_parsers import XMLOutputParser\n",
    "output_parser=XMLOutputParser()\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are an expert AI Engineer.<response><answer>Your answer here</answer></response>.Provide me answer based on the question\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "96488938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['query'], input_types={}, partial_variables={'format_instruction': 'The output should be formatted as a XML file.\\n1. Output should conform to the tags below.\\n2. If tags are not given, make them on your own.\\n3. Remember to always open and close all the tags.\\n\\nAs an example, for the tags [\"foo\", \"bar\", \"baz\"]:\\n1. String \"<foo>\\n   <bar>\\n      <baz></baz>\\n   </bar>\\n</foo>\" is a well-formatted instance of the schema.\\n2. String \"<foo>\\n   <bar>\\n   </foo>\" is a badly-formatted instance.\\n3. String \"<foo>\\n   <tag>\\n   </tag>\\n</foo>\" is a badly-formatted instance.\\n\\nHere are the output tags:\\n```\\nNone\\n```'}, template='Answer the user query \\n {format_instruction}\\n {query}\\n ')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### OutputParser\n",
    "from langchain_core.output_parsers import XMLOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "output_parser=XMLOutputParser()\n",
    "\n",
    "prompt=PromptTemplate(\n",
    "    template=\"Answer the user query \\n {format_instruction}\\n {query}\\n \",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instruction\":output_parser.get_format_instructions()},\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f7b96ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='```xml\\n<response>\\n  <name>Langsmith</name>\\n  <description>Langsmith is an open-source platform for building and deploying AI applications.</description>\\n  <features>\\n    <feature>Supports multiple programming languages, including Python and JavaScript.</feature>\\n    <feature>Provides a visual interface for building AI models.</feature>\\n    <feature>Offers a marketplace for sharing and discovering AI models.</feature>\\n    <feature>Enables easy integration with other tools and services.</feature>\\n  </features>\\n  <website>https://www.langsmith.com</website>\\n</response>\\n``` \\n' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 141, 'prompt_tokens': 195, 'total_tokens': 336, 'completion_time': 0.256363636, 'prompt_time': 0.007823398, 'queue_time': 0.245099288, 'total_time': 0.264187034}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None} id='run--36e76e7a-e23a-4a91-a3cf-f2ea3f0655b8-0' usage_metadata={'input_tokens': 195, 'output_tokens': 141, 'total_tokens': 336}\n"
     ]
    }
   ],
   "source": [
    "chain=prompt|model\n",
    "response=chain.invoke({\"query\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa97352",
   "metadata": {},
   "source": [
    "- `ChatPromptTemplate` :'When u needed the Conversion'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6d3f4c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='<response><answer>LangChain is a framework designed to simplify the development of applications powered by large language models (LLMs). It offers a modular and extensible way to build chains of LLM calls, connect them to external data sources, and manage their interactions.</answer></response>\\n' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 60, 'prompt_tokens': 39, 'total_tokens': 99, 'completion_time': 0.109090909, 'prompt_time': 0.002360436, 'queue_time': 0.242157451, 'total_time': 0.111451345}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None} id='run--9229bbbe-67b3-43c7-a66d-e943d7262196-0' usage_metadata={'input_tokens': 39, 'output_tokens': 60, 'total_tokens': 99}\n"
     ]
    }
   ],
   "source": [
    "##output parser\n",
    "#from langchain_core.output_parsers import XMLOutputParser\n",
    "from langchain.output_parsers.xml import XMLOutputParser\n",
    "\n",
    "# XML Output Parser\n",
    "output_parser = XMLOutputParser()\n",
    "\n",
    "# Prompt that instructs the model to return XML\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant. Respond in this XML format: <response><answer>Your answer here</answer></response>\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "# Build the chain\n",
    "chain = prompt | model\n",
    "\n",
    "# Run the chain\n",
    "#response = chain.invoke({\"input\": \"What is LangChain?\"})\n",
    "\n",
    "raw_output =chain.invoke({\"input\": \"What is LangChain?\"})\n",
    "\n",
    "# Print result\n",
    "print(raw_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d189d4c9",
   "metadata": {},
   "source": [
    "### With Pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b7c4345f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'setup': \"Why couldn't the bicycle stand up by itself?\",\n",
       " 'punchline': 'Because it was two tired!'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## With Pydantic\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "model = ChatOpenAI(temperature=0.7)\n",
    "\n",
    "\n",
    "# Define your desired data structure.\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"question to set up a joke\")\n",
    "    punchline: str = Field(description=\"answer to resolve the joke\")\n",
    "\n",
    "\n",
    "# And a query intented to prompt a language model to populate the data structure.\n",
    "joke_query = \"Tell me a joke.\"\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = JsonOutputParser(pydantic_object=Joke)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | model | parser\n",
    "\n",
    "chain.invoke({\"query\": joke_query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e73b76ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'joke': \"Why couldn't the bicycle stand up by itself? Because it was two tired!\"}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Without Pydantic\n",
    "joke_query = \"Tell me a joke .\"\n",
    "\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | model | parser\n",
    "\n",
    "chain.invoke({\"query\": joke_query})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8d60ee",
   "metadata": {},
   "source": [
    "### XMLOutputParser "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c7bd1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<movie>Big</movie>\n",
      "<movie>Saving Private Ryan</movie>\n",
      "<movie>Forrest Gump</movie>\n",
      "<movie>Cast Away</movie>\n",
      "<movie>Apollo 13</movie>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_core.output_parsers import XMLOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "actor_query = \"Generate the shortened filmography for Tom Hanks.\"\n",
    "\n",
    "output = model.invoke(\n",
    "    f\"\"\"{actor_query}\n",
    "Please enclose the movies in <movie></movie> tags\"\"\"\n",
    ")\n",
    "\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ce3544",
   "metadata": {},
   "source": [
    "### Yaml Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "08b728f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Joke(setup=\"Why couldn't the bicycle stand up by itself?\", punchline='Because it was two-tired!')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.output_parsers import YamlOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "# Define your desired data structure.\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"question to set up a joke\")\n",
    "    punchline: str = Field(description=\"answer to resolve the joke\")\n",
    "\n",
    "\n",
    "model = ChatOpenAI(temperature=0.5)\n",
    "\n",
    "# And a query intented to prompt a language model to populate the data structure.\n",
    "joke_query = \"Tell me a joke.\"\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = YamlOutputParser(pydantic_object=Joke)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | model | parser\n",
    "\n",
    "chain.invoke({\"query\": joke_query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12093ef4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da6ab23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
